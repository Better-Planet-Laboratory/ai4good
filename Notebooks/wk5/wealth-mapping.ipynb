{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poverty & Wealth Mapping\n",
    "\n",
    "\n",
    "\"Despite decades of declining poverty rates, an estimated 8.4% of the global population remains in extreme poverty as of 2019, and progress has slowed in recent years [1]. But data on poverty remain surprisingly sparse, hampering efforts at monitoring local progress, targeting aid to those who need it, and evaluating the effectiveness of antipoverty programs [2]. Previous works [3,4] have demonstrated using computer vision on satellite images and street-level images to predict economic livelihood.\" [5]\n",
    "\n",
    "In this notebook, we will pull a 2021 benchmark dataset from the Stanford Sustainability and AI Lab called \"SustainBench\". This dataset contains a variety of datasets related to sustainability, including datasets related to poverty and wealth mapping. More info on it can be found on the [project website](https://sustainlab-group.github.io/sustainbench/), the [GitHub repo](https://github.com/sustainlab-group/sustainbench), or the [arXiv paper](https://arxiv.org/abs/2111.04724). The data comes from surveys collected by the [Demographic and Health Surveys (DHS) Program](https://dhsprogram.com/) from USAID (RIP üò¢). Nationally represenative surveys are conducted every few years in dozens of low- and middle-income countries (LMICs) around the world. Surveyors will go out to urban neigborhoods or rural communities and survey a few dozen random households within that \"cluster\". The anonymized household level data is geotagged with the coordinates of the cluster with a jitter to further protect privacy. The jitter is within a 2km radius for urban clusters, and a 5km radius for rural clusters. We will focus on Task 1A from SustainBench, mapping wealth and poverty spatially. SustainBench has made our lives easier by collating this data for 80k+ clusters and making it publicly avaiable, but you can request the original and latest household-level data directly from the [DHS on their website](https://dhsprogram.com/data/available-datasets.cfm), it takes just a couple of days to get approved.\n",
    "\n",
    "![sustainbench](https://sustainlab-group.github.io/sustainbench/assets/images/sdg1_summary.png)\n",
    "\n",
    "\n",
    "We then will pull in 3 geospatial foundation models that use three different architectures:\n",
    "1. [CLAY](https://madewithclay.org/) (pre-trained with a masked autoencoder)\n",
    "2. [SatCLIP](https://github.com/microsoft/satclip) (pre-trained with contrastive learning)\n",
    "3. [MOSAIKS](https://www.mosaiks.org/) (random convolutional features)\n",
    "\n",
    "We will then use these models to extract features from the poverty and wealth mapping dataset, and then train a linear classifier on top of these features to predict the poverty and wealth labels. We will then evaluate the performance of each model on the test set.\n",
    "\n",
    "### References\n",
    "\n",
    "[1] United Nations Department of Economic and Social Affairs. The Sustainable Development Goals Report 2021. The Sustainable Development Goals Report. United Nations, 2021 edition, 2021. ISBN 978-92-1-005608-3. doi: 10.18356/9789210056083. URL https://www.un-ilibrary.org/content/books/9789210056083.\n",
    "\n",
    "[2] M. Burke, A. Driscoll, D. B. Lobell, and S. Ermon. Using satellite imagery to understand and promote sustainable development. Science, 371(6535), 2021. doi: 10.1126/science.448abe8628. URL https://www.science.org/doi/10.1126/science.abe8628.\n",
    "\n",
    "[3] C. Yeh, A. Perez, A. Driscoll, G. Azzari, Z. Tang, D. Lobell, S. Ermon, and M. Burke. Using publicly available satellite imagery and deep learning to understand economic well-being in Africa. Nature Communications, 11(1), 5 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-58916185-w. URL https://www.nature.com/articles/s41467-020-16185-w.\n",
    "\n",
    "[4] J. Lee, D. Grosz, B. Uzkent, S. Zeng, M. Burke, D. Lobell, and S. Ermon. Predicting Livelihood Indicators from Community-Generated Street-Level Imagery. Proceedings of the AAAI Conference on Artificial Intelligence, 35(1):268‚Äì276, 5 2021. ISSN 2374-3468. URL https://ojs.aaai.org/index.php/AAAI/article/view/16101.\n",
    "\n",
    "[5] C. Yeh, C. Meng, S. Wang, A. Driscoll, E. Rozi, P. Liu, J. Lee, M. Burke, D. Lobell, and S. Ermon, ‚ÄúSustainBench: Benchmarks for Monitoring the Sustainable Development Goals with Machine Learning,‚Äù in Thirty-fifth Conference on Neural Information Processing Systems, Datasets and Benchmarks Track (Round 2), Dec. 2021. [Online]. Available: https://openreview.net/forum?id=5HR3vCylqD.\n",
    "\n",
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install any libraries that are missing\n",
    "# !pip install geopandas\n",
    "# !pip install lonboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "from lonboard import viz\n",
    "\n",
    "# set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"imported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and Visualize Dataset\n",
    "Every good data scientists knows that you need to visualize your data to understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHSID_EA</th>\n",
       "      <th>cname</th>\n",
       "      <th>year</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>n_asset</th>\n",
       "      <th>asset_index</th>\n",
       "      <th>n_water</th>\n",
       "      <th>water_index</th>\n",
       "      <th>n_sanitation</th>\n",
       "      <th>...</th>\n",
       "      <th>n_under5_mort</th>\n",
       "      <th>women_edu</th>\n",
       "      <th>women_bmi</th>\n",
       "      <th>n_women_edu</th>\n",
       "      <th>n_women_bmi</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>adm1fips</th>\n",
       "      <th>adm1dhs</th>\n",
       "      <th>urban</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL-2008-5#-00000001</td>\n",
       "      <td>AL</td>\n",
       "      <td>2008</td>\n",
       "      <td>40.822652</td>\n",
       "      <td>19.838321</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.430596</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>24.365000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999</td>\n",
       "      <td>R</td>\n",
       "      <td>POINT (19.83832 40.82265)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL-2008-5#-00000002</td>\n",
       "      <td>AL</td>\n",
       "      <td>2008</td>\n",
       "      <td>40.696846</td>\n",
       "      <td>20.007555</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.867678</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>23.104000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999</td>\n",
       "      <td>R</td>\n",
       "      <td>POINT (20.00755 40.69685)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL-2008-5#-00000003</td>\n",
       "      <td>AL</td>\n",
       "      <td>2008</td>\n",
       "      <td>40.750037</td>\n",
       "      <td>19.974262</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.909049</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>22.387778</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999</td>\n",
       "      <td>R</td>\n",
       "      <td>POINT (19.97426 40.75004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL-2008-5#-00000004</td>\n",
       "      <td>AL</td>\n",
       "      <td>2008</td>\n",
       "      <td>40.798931</td>\n",
       "      <td>19.863338</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.881122</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.947368</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.952381</td>\n",
       "      <td>27.084500</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999</td>\n",
       "      <td>R</td>\n",
       "      <td>POINT (19.86334 40.79893)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL-2008-5#-00000005</td>\n",
       "      <td>AL</td>\n",
       "      <td>2008</td>\n",
       "      <td>40.746123</td>\n",
       "      <td>19.843885</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.546830</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.684211</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.937500</td>\n",
       "      <td>24.523125</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999</td>\n",
       "      <td>R</td>\n",
       "      <td>POINT (19.84389 40.74612)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DHSID_EA cname  year        lat        lon  n_asset  \\\n",
       "0  AL-2008-5#-00000001    AL  2008  40.822652  19.838321     18.0   \n",
       "1  AL-2008-5#-00000002    AL  2008  40.696846  20.007555     20.0   \n",
       "2  AL-2008-5#-00000003    AL  2008  40.750037  19.974262     18.0   \n",
       "3  AL-2008-5#-00000004    AL  2008  40.798931  19.863338     19.0   \n",
       "4  AL-2008-5#-00000005    AL  2008  40.746123  19.843885     19.0   \n",
       "\n",
       "   asset_index  n_water  water_index  n_sanitation  ...  n_under5_mort  \\\n",
       "0     2.430596     18.0     3.444444          18.0  ...            6.0   \n",
       "1     2.867678     20.0     4.700000          20.0  ...            NaN   \n",
       "2     2.909049     18.0     4.500000          18.0  ...            NaN   \n",
       "3     2.881122     19.0     4.947368          19.0  ...            NaN   \n",
       "4     2.546830     19.0     4.684211          19.0  ...            6.0   \n",
       "\n",
       "   women_edu  women_bmi  n_women_edu  n_women_bmi  cluster_id  adm1fips  \\\n",
       "0   9.500000  24.365000         18.0         18.0           1       NaN   \n",
       "1   8.600000  23.104000         20.0         20.0           2       NaN   \n",
       "2   9.666667  22.387778         18.0         18.0           3       NaN   \n",
       "3   9.952381  27.084500         21.0         20.0           4       NaN   \n",
       "4   8.937500  24.523125         16.0         16.0           5       NaN   \n",
       "\n",
       "   adm1dhs urban                   geometry  \n",
       "0     9999     R  POINT (19.83832 40.82265)  \n",
       "1     9999     R  POINT (20.00755 40.69685)  \n",
       "2     9999     R  POINT (19.97426 40.75004)  \n",
       "3     9999     R  POINT (19.86334 40.79893)  \n",
       "4     9999     R  POINT (19.84389 40.74612)  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the csv file\n",
    "df = pd.read_csv(\"~/code/ai4good/data/wk5/dhs_final_labels.csv\")\n",
    "\n",
    "# now convert this regular dataframe into a nifty geopandas dataframe\n",
    "# learn more about what a \"geo\" dataframe is here: https://geopandas.org/en/stable/docs/user_guide/data_structures.html#geodataframe\n",
    "# it's based on Python Shapely geometries: https://shapely.readthedocs.io/en/stable/geometry.html\n",
    "# which is in turn based on C/C++ GEOS geometries: https://libgeos.org/usage/\n",
    "# which is in turn based on the OGC Simple Features standard: https://en.wikipedia.org/wiki/Simple_Features\n",
    "# which describes well-known text (WKT) representations of vector geometry: https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry\n",
    "# fun!\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat), crs=\"EPSG:4326\")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4e6ebc90964834a600c9ac038825cb",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(basemap_style=<CartoBasemap.DarkMatter: 'https://basemaps.cartocdn.com/gl/dark-matter-gl-style/style.json'‚Ä¶"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize with lonboard from Development Seed built on top of deck.gl\n",
    "# learn more about it at https://github.com/developmentseed/lonboard or in the documentation here https://developmentseed.org/lonboard/latest/\n",
    "# hover over the points to see the data labels\n",
    "viz(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of clusters! Thanks `lonboard` for loading it all so quickly. What are some countries missing from this dataset? Why do you think DHS didn't include them? Could this lead to potential biases? ü§î\n",
    "\n",
    "## Geospatial Foundation Models\n",
    "Since we aren't going to be doing any training in this notebook, we don't need the inputs from SustainBench, we'll just use the labels. Each of the foundation models that we're going to be using can take in a given lat/long and return a vector of embeddings. Let's fetch those embeddings for each of the clusters in our dataset one model at a time.\n",
    "\n",
    "### CLAY\n",
    "https://clay-foundation.github.io/model/index.html\n",
    "\n",
    "### MOSAIKS\n",
    "MULTI-TASK OBSERVATION USING SATELLITE IMAGERY & KITCHEN SINKS\n",
    "Nature Paper: https://www.nature.com/articles/s41467-021-24638-z\n",
    "Website with API: https://api.mosaiks.org/portal/index/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaiah/miniconda3/envs/tg/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.mosaiks.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading https://api.mosaiks.org/portal/download_grid_file/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Oceania.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "oceania_1.zip: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 133M/133M [00:09<00:00, 15.5MB/s] \n",
      "/Users/isaiah/miniconda3/envs/tg/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.mosaiks.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded: /Users/isaiah/code/ai4good/data/wk5/mosaiks/oceania_1.zip\n",
      "üì• Downloading https://api.mosaiks.org/portal/download_grid_file/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Australia.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "australia_1.zip: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.48G/1.48G [01:39<00:00, 16.0MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded: /Users/isaiah/code/ai4good/data/wk5/mosaiks/australia_1.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cookie for authentication\n",
    "COOKIE = {\n",
    "    \"csrftoken\": \"I9x2jvGGE4se3MBa9moavDtC9o8YEgaA4Rup5ijhHJjCTRn0qRpHGJW06XG0SooG\",\n",
    "    \"sessionid\": \"y44nlmh7rjrqvvxj902jc8pmw918m1p7\",\n",
    "}\n",
    "\n",
    "# Base URL for file downloads\n",
    "BASE_URL = \"https://api.mosaiks.org/portal/download_grid_file/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True\"\n",
    "\n",
    "# Destination directory\n",
    "DEST_DIR = \"/Users/isaiah/code/ai4good/data/wk5/mosaiks\"\n",
    "os.makedirs(DEST_DIR, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Regions and chunks to download\n",
    "regions = {\n",
    "    # \"Africa\": [1, 2, 3],\n",
    "    # \"Asia\": [1, 2, 3, 4, 5, 6],\n",
    "    # \"Europe\": [1, 2],\n",
    "    # \"North America\": [1, 2, 3],\n",
    "    \"Oceania\": [1],\n",
    "    # \"South America\": [1, 2],\n",
    "    \"Australia\": [1],\n",
    "}\n",
    "\n",
    "# Function to download a file with progress bar\n",
    "def download_file(url, filename):\n",
    "    response = requests.get(url, cookies=COOKIE, stream=True, verify=False)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        total_size = int(response.headers.get(\"content-length\", 0))\n",
    "        with open(filename, \"wb\") as f, tqdm(\n",
    "            desc=os.path.basename(filename),\n",
    "            total=total_size,\n",
    "            unit=\"B\",\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "                bar.update(len(chunk))\n",
    "        print(f\"‚úÖ Downloaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to download {url} (Status {response.status_code})\")\n",
    "\n",
    "# Download each file\n",
    "for region, chunks in regions.items():\n",
    "    for chunk in chunks:\n",
    "        filename = os.path.join(DEST_DIR, f\"{region.lower()}_{chunk}.zip\")\n",
    "        url = f\"{BASE_URL}/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_{region}_chunk={chunk}.zip\"\n",
    "        if (region == \"Australia\" or region == \"Oceania\"):\n",
    "            url = f\"{BASE_URL}/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_{region}.zip\"\n",
    "        \n",
    "        print(f\"üì• Downloading {url}...\")\n",
    "        download_file(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/europe_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/europe_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_3.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/north america_3.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_6.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/north america_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_5.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_4.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/north america_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/africa_3.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/africa_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/africa_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/south america_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n",
      "Extracted /Users/isaiah/code/ai4good/data/wk5/mosaiks/south america_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/\n"
     ]
    }
   ],
   "source": [
    "# unzip the files\n",
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory containing the zip files\n",
    "zip_dir = \"/Users/isaiah/code/ai4good/data/wk5/mosaiks\"\n",
    "# Define the directory to extract the contents\n",
    "extract_dir = \"/Users/isaiah/code/ai4good/data/wk5/mosaiks/\"\n",
    "# Create the extraction directory if it doesn't exist\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "# Loop through all zip files in the directory\n",
    "for zip_file in glob.glob(os.path.join(zip_dir, \"*.zip\")):\n",
    "    # Open the zip file\n",
    "    with zipfile.ZipFile(zip_file, \"r\") as z:\n",
    "        # Extract all the contents into the extraction directory\n",
    "        z.extractall(extract_dir)\n",
    "        print(f\"Extracted {zip_file} to {extract_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Africa_chunk=2.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Africa_chunk=2.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/europe_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/europe_2.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Africa_chunk=3.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Africa_chunk=3.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Africa_chunk=1.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Africa_chunk=1.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/europe_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/europe_1.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Europe_chunk=1.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Europe_chunk=1.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_North America_chunk=2.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_North_America_chunk=2.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_North America_chunk=3.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_North_America_chunk=3.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Europe_chunk=2.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Europe_chunk=2.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_North America_chunk=1.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_North_America_chunk=1.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_1.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_3.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_3.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_2.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/north america_3.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/north_america_3.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_6.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_6.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/north america_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/north_america_2.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_5.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_5.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_4.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/asia_4.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/north america_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/north_america_1.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_South America_chunk=2.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_South_America_chunk=2.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/africa_3.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/africa_3.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=1.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=1.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/africa_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/africa_2.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_South America_chunk=1.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_South_America_chunk=1.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=3.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=3.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=2.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=2.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/africa_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/africa_1.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=6.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=6.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/south america_1.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/south_america_1.zip\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=5.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=5.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=4.csv to /Users/isaiah/code/ai4good/data/wk5/mosaiks/coarsened_global_dense_grid_decimal_place=1_GHS_pop_weight=True_Asia_chunk=4.csv\n",
      "Renamed /Users/isaiah/code/ai4good/data/wk5/mosaiks/south america_2.zip to /Users/isaiah/code/ai4good/data/wk5/mosaiks/south_america_2.zip\n"
     ]
    }
   ],
   "source": [
    "# replace all \" \" in the filenames with \"_\"\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Define the directory containing the files\n",
    "directory = \"/Users/isaiah/code/ai4good/data/wk5/mosaiks/\"\n",
    "# Loop through all files in the directory\n",
    "for filename in glob.glob(os.path.join(directory, \"*\")):\n",
    "    # Replace spaces with underscores\n",
    "    new_filename = re.sub(r\"\\s+\", \"_\", filename)\n",
    "    # Rename the file\n",
    "    os.rename(filename, new_filename)\n",
    "    print(f\"Renamed {filename} to {new_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the csv files into one for each continent\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "csv_dir = \"/Users/isaiah/code/ai4good/data/wk5/mosaiks/\"\n",
    "# Define the output directory for the combined CSV files\n",
    "output_dir = \"/Users/isaiah/code/ai4good/data/wk5/mosaiks/\"\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Loop through each continent\n",
    "for continent in [\"Europe\", \"North_America\", \"South_America\", \"Oceania\", \"Asia\"]:\n",
    "    print(f\"Combining {continent} files...\")\n",
    "    # Find all CSV files for the continent\n",
    "    csv_files = glob.glob(os.path.join(csv_dir, f\"*{continent}_*.csv\"))\n",
    "    # Combine the CSV files into one DataFrame\n",
    "    print(f\"Combining {len(csv_files)} files...\")\n",
    "    combined_df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "    # Save the combined DataFrame to a new CSV file\n",
    "    combined_df.to_csv(os.path.join(output_dir, f\"{continent}.csv\"), index=False)\n",
    "    print(f\"Combined {len(csv_files)} files into {continent}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for MOSAIKS Embeddings\n",
    "Now we need to match up our locations with the MOSAIKS locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"~/code/ai4good/data/wk5/dhs_final_labels.csv\")\n",
    "\n",
    "# Assign coordinates to nearest tile centroid\n",
    "df[\"Lon\"] = round(round(df[\"lon\"] + 0.5, 0) - 0.5, 1)\n",
    "df[\"Lat\"] = round(round(df[\"lat\"] + 0.5, 0) - 0.5, 1)\n",
    "\n",
    "# Remove original coordinates\n",
    "df = df.drop(columns=[\"lon\", \"lat\"])\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "df_gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"Lon\"], df[\"Lat\"]), crs=\"EPSG:4326\")\n",
    "\n",
    "viz(df_gdf)\n",
    "\n",
    "# Write to CSV\n",
    "df.to_csv(\"dhs_final_labels_centered_1_deg.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do\n",
    "- [ ] Get the precise embeddings from the MOSAIKS folks\n",
    "- [ ] Work with the 1.0 degrees for now\n",
    "- [ ] Join the MOSAIKS embeddings with the SustainBench data\n",
    "- [ ] Run Ridge regression on the MOSAIKS embeddings with poverty as the label\n",
    "- [ ] Report on the results\n",
    "- [ ] Compare with CLAY and SatCLIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
