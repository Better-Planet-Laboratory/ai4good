{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngz8zz9Gvbxh"
   },
   "source": [
    "# Part 3: SatCLIP\n",
    "\n",
    "SatCLIP is a model that was trained on 1.5B geotagged images from the internet. It uses a contrastive learning approach to learn representations of satellite imagery. You can read more about it in the [paper](https://arxiv.org/abs/2311.17179) or check out the [GitHub repo](https://github.com/microsoft/satclip/).\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "We start by setting up **SatCLIP** code and installing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:42:33.411988Z",
     "iopub.status.busy": "2025-02-07T20:42:33.411681Z",
     "iopub.status.idle": "2025-02-07T20:42:35.243025Z",
     "shell.execute_reply": "2025-02-07T20:42:35.242163Z",
     "shell.execute_reply.started": "2025-02-07T20:42:33.411966Z"
    },
    "id": "tD7wze7andRh",
    "outputId": "b4949082-62e9-474b-f62d-fd234982d03d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/microsoft/satclip.git # Clone SatCLIP repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:42:54.696952Z",
     "iopub.status.busy": "2025-02-07T20:42:54.696600Z",
     "iopub.status.idle": "2025-02-07T20:43:08.848593Z",
     "shell.execute_reply": "2025-02-07T20:43:08.847424Z",
     "shell.execute_reply.started": "2025-02-07T20:42:54.696925Z"
    },
    "id": "Q72Ypu0Cr3Sc",
    "outputId": "9e922bc4-c78d-4a24-9ed8-f9f6616445c8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install lightning --quiet\n",
    "!pip install rasterio --quiet\n",
    "!pip install torchgeo --quiet\n",
    "!pip install basemap --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmcZKqU9wOTk"
   },
   "source": [
    "Chose a SatCLIP model from the list of available pretrained models [here](https://github.com/microsoft/satclip#pretrained-models). They all perform somewhat similarly. Let's download a SatCLIP using a ViT16 vision encoder and $L=10$ Legendre polynomials in the location encoder (i.e., a low-resolution SatCLIP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:43:42.219532Z",
     "iopub.status.busy": "2025-02-07T20:43:42.219192Z",
     "iopub.status.idle": "2025-02-07T20:43:45.394764Z",
     "shell.execute_reply": "2025-02-07T20:43:45.393766Z",
     "shell.execute_reply.started": "2025-02-07T20:43:42.219505Z"
    },
    "id": "N4S7_2fqqWF1",
    "outputId": "e78e14b6-f53a-40f7-d6f2-6bf232f04013",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-07 14:16:13--  https://satclip.z13.web.core.windows.net/satclip/satclip-resnet18-l40.ckpt\n",
      "Resolving satclip.z13.web.core.windows.net (satclip.z13.web.core.windows.net)... 52.239.221.231\n",
      "Connecting to satclip.z13.web.core.windows.net (satclip.z13.web.core.windows.net)|52.239.221.231|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75633927 (72M) [application/zip]\n",
      "Saving to: ‘satclip-resnet18-l40.ckpt’\n",
      "\n",
      "satclip-resnet18-l4 100%[===================>]  72.13M  6.59MB/s    in 14s     \n",
      "\n",
      "2025-02-07 14:16:27 (5.23 MB/s) - ‘satclip-resnet18-l40.ckpt’ saved [75633927/75633927]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://satclip.z13.web.core.windows.net/satclip/satclip-resnet18-l40.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_FUpXihwwpB"
   },
   "source": [
    "Load required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T20:44:36.310501Z",
     "iopub.status.busy": "2025-02-07T20:44:36.310210Z",
     "iopub.status.idle": "2025-02-07T20:44:36.315552Z",
     "shell.execute_reply": "2025-02-07T20:44:36.314811Z",
     "shell.execute_reply.started": "2025-02-07T20:44:36.310479Z"
    },
    "id": "grEIwoFjoHvu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./satclip/satclip')\n",
    "\n",
    "import torch\n",
    "from load import get_satclip\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Automatically select device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JthxyqHsqozM"
   },
   "source": [
    "## Get air temperature dataset\n",
    "\n",
    "In this example, we work with a dataset of annual mean temperature values recorded at ~3000 locations around the planet introduced [here](https://www.nature.com/articles/sdata2018246). To download the dataset, we can use code from the [PE-GNN repository](https://github.com/konstantinklemmer/pe-gnn/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T20:44:49.699121Z",
     "iopub.status.busy": "2025-02-07T20:44:49.698784Z",
     "iopub.status.idle": "2025-02-07T20:44:49.705110Z",
     "shell.execute_reply": "2025-02-07T20:44:49.704237Z",
     "shell.execute_reply.started": "2025-02-07T20:44:49.699097Z"
    },
    "id": "fvNnJtpEq31R",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_air_temp_data(pred=\"temp\",norm_y=True,norm_x=True):\n",
    "  '''\n",
    "  Download and process the Global Air Temperature dataset (more info: https://www.nature.com/articles/sdata2018246)\n",
    "\n",
    "  Parameters:\n",
    "  pred = numeric; outcome variable to be returned; choose from [\"temp\", \"prec\"]\n",
    "  norm_y = logical; should outcome be normalized\n",
    "  norm_min_val = integer; choice of [0,1], setting whether normalization in range[0,1] or [-1,1]\n",
    "\n",
    "  Return:\n",
    "  coords = spatial coordinates (lon/lat)\n",
    "  x = features at location\n",
    "  y = outcome variable\n",
    "  '''\n",
    "  url = 'https://springernature.figshare.com/ndownloader/files/12609182'\n",
    "  url_open = request.urlopen(url)\n",
    "  inc = np.array(pd.read_csv(io.StringIO(url_open.read().decode('utf-8'))))\n",
    "  coords = inc[:,:2]\n",
    "  if pred==\"temp\":\n",
    "    y = inc[:,4].reshape(-1)\n",
    "    x = inc[:,5]\n",
    "  else:\n",
    "    y = inc[:,5].reshape(-1)\n",
    "    x = inc[:,4]\n",
    "  if norm_y==True:\n",
    "    y = y / y.max()\n",
    "  if norm_x==True:\n",
    "    x = x / x.max()\n",
    "\n",
    "  return torch.tensor(coords), torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T20:44:53.588544Z",
     "iopub.status.busy": "2025-02-07T20:44:53.588233Z",
     "iopub.status.idle": "2025-02-07T20:44:54.979990Z",
     "shell.execute_reply": "2025-02-07T20:44:54.979319Z",
     "shell.execute_reply.started": "2025-02-07T20:44:53.588519Z"
    },
    "id": "8QFfrQUysNZ2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "coords, _, y = get_air_temp_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGR2jSZLsiUx"
   },
   "source": [
    "Let's plot our data. Here we show a map of the world with our locations colored by mean temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:44:57.266449Z",
     "iopub.status.busy": "2025-02-07T20:44:57.266146Z",
     "iopub.status.idle": "2025-02-07T20:44:57.803230Z",
     "shell.execute_reply": "2025-02-07T20:44:57.802327Z",
     "shell.execute_reply.started": "2025-02-07T20:44:57.266424Z"
    },
    "id": "hmZmDOXPst0y",
    "outputId": "8f3338c8-556a-4937-fa50-bc54d236e6b3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(5, 3))\n",
    "\n",
    "m = Basemap(projection='cyl', resolution='c', ax=ax)\n",
    "m.drawcoastlines()\n",
    "ax.scatter(coords[:,0], coords[:,1], c=y, s=5)\n",
    "ax.set_title('Annual Mean Temperatures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHUQyTODt1UX"
   },
   "source": [
    "## Predictive modeling\n",
    "\n",
    "We now want to predict annual mean temperature values using SatCLIP embeddings. First, we need to obtain the location embeddings for our dataset from the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T20:45:38.384421Z",
     "iopub.status.busy": "2025-02-07T20:45:38.384131Z",
     "iopub.status.idle": "2025-02-07T20:45:40.497463Z",
     "shell.execute_reply": "2025-02-07T20:45:40.496812Z",
     "shell.execute_reply.started": "2025-02-07T20:45:38.384400Z"
    },
    "id": "AFkpE1d7q9yW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "satclip_path = 'satclip-resnet18-l40.ckpt'\n",
    "\n",
    "model = get_satclip(satclip_path, device=device) # Only loads location encoder by default\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  x  = model(coords.double().to(device)).detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaNU4D96us9O"
   },
   "source": [
    "We have now collected a 256-dimensional location embedding for each latitude/longitude coordinate in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:45:45.415030Z",
     "iopub.status.busy": "2025-02-07T20:45:45.414656Z",
     "iopub.status.idle": "2025-02-07T20:45:45.419951Z",
     "shell.execute_reply": "2025-02-07T20:45:45.419074Z",
     "shell.execute_reply.started": "2025-02-07T20:45:45.415003Z"
    },
    "id": "DY-yS8cNru7w",
    "outputId": "8e6a1c89-9da2-4a9e-a3ff-568b0ba7a812",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(coords.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hj1Hqqtru51Y"
   },
   "source": [
    "Next, let's split our dataset into 50% training and 50% testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T20:45:51.311201Z",
     "iopub.status.busy": "2025-02-07T20:45:51.310902Z",
     "iopub.status.idle": "2025-02-07T20:45:51.323485Z",
     "shell.execute_reply": "2025-02-07T20:45:51.322572Z",
     "shell.execute_reply.started": "2025-02-07T20:45:51.311179Z"
    },
    "id": "z0N5oeZ9u0sV",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(coords, x, y)\n",
    "\n",
    "train_size = int(0.5 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "coords_train, x_train, y_train = train_set.dataset.tensors[0][train_set.indices], train_set.dataset.tensors[1][train_set.indices], train_set.dataset.tensors[2][train_set.indices]\n",
    "coords_test, x_test, y_test = test_set.dataset.tensors[0][test_set.indices], test_set.dataset.tensors[1][test_set.indices], test_set.dataset.tensors[2][test_set.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:45:54.463453Z",
     "iopub.status.busy": "2025-02-07T20:45:54.463173Z",
     "iopub.status.idle": "2025-02-07T20:45:54.911408Z",
     "shell.execute_reply": "2025-02-07T20:45:54.910540Z",
     "shell.execute_reply.started": "2025-02-07T20:45:54.463432Z"
    },
    "id": "adCdPHwwwXWM",
    "outputId": "768ef32d-9ba1-442f-c2fa-8ad80334b301",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(5, 3))\n",
    "\n",
    "m = Basemap(projection='cyl', resolution='c', ax=ax)\n",
    "m.drawcoastlines()\n",
    "ax.scatter(coords_train[:,0], coords_train[:,1], c='blue', s=2, label='Training',alpha=0.5)\n",
    "ax.scatter(coords_test[:,0], coords_test[:,1], c='green', s=2, label='Testing',alpha=0.5)\n",
    "ax.legend()\n",
    "ax.set_title('Train-Test Split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAAOVBdIxF_X"
   },
   "source": [
    "Next we define our prediction model, a simple MLP. (NOTE: SatCLIP embeddings can of course be used with any predictive model, we just opt for an MLP here for simplicity. You can also directly unfreeze the location encoder `model` above and fine-tune it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T20:45:59.409674Z",
     "iopub.status.busy": "2025-02-07T20:45:59.409339Z",
     "iopub.status.idle": "2025-02-07T20:45:59.415412Z",
     "shell.execute_reply": "2025-02-07T20:45:59.414482Z",
     "shell.execute_reply.started": "2025-02-07T20:45:59.409648Z"
    },
    "id": "FW65kkGexL9U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, dim_hidden, num_layers, out_dims):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers += [nn.Linear(input_dim, dim_hidden, bias=True), nn.ReLU()] # Input layer\n",
    "        layers += [nn.Linear(dim_hidden, dim_hidden, bias=True), nn.ReLU()] * num_layers # Hidden layers\n",
    "        layers += [nn.Linear(dim_hidden, out_dims, bias=True)] # Output layer\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:46:08.785180Z",
     "iopub.status.busy": "2025-02-07T20:46:08.784897Z",
     "iopub.status.idle": "2025-02-07T20:46:08.790052Z",
     "shell.execute_reply": "2025-02-07T20:46:08.789214Z",
     "shell.execute_reply.started": "2025-02-07T20:46:08.785160Z"
    },
    "id": "CfsgJLJuqEtv",
    "outputId": "11c13a15-e73a-4683-c0de-4a90cb827650",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufbqVygqxpOq"
   },
   "source": [
    "Let's set up and run the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:46:12.283267Z",
     "iopub.status.busy": "2025-02-07T20:46:12.282669Z",
     "iopub.status.idle": "2025-02-07T20:46:19.036533Z",
     "shell.execute_reply": "2025-02-07T20:46:19.035610Z",
     "shell.execute_reply.started": "2025-02-07T20:46:12.283225Z"
    },
    "id": "di_SelDzxkjD",
    "outputId": "e9803126-e726-4d5d-e391-1b8281b810d8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_model = MLP(input_dim=256, dim_hidden=64, num_layers=2, out_dims=1).float().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(pred_model.parameters(), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "epochs = 3000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  optimizer.zero_grad()\n",
    "  # Forward pass\n",
    "  y_pred = pred_model(x_train.float().to(device))\n",
    "  # Compute the loss\n",
    "  loss = criterion(y_pred.reshape(-1), y_train.float().to(device))\n",
    "  # Backward pass\n",
    "  loss.backward()\n",
    "  # Update the parameters\n",
    "  optimizer.step()\n",
    "  # Append the loss to the list\n",
    "  losses.append(loss.item())\n",
    "  if (epoch + 1) % 250 == 0:\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkViMvRD0JsJ"
   },
   "source": [
    "Let's make predictions on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:46:28.121446Z",
     "iopub.status.busy": "2025-02-07T20:46:28.121132Z",
     "iopub.status.idle": "2025-02-07T20:46:28.127846Z",
     "shell.execute_reply": "2025-02-07T20:46:28.127072Z",
     "shell.execute_reply.started": "2025-02-07T20:46:28.121420Z"
    },
    "id": "OIqIGJc7zPTe",
    "outputId": "6f22edbb-cbae-4979-b7a5-f1a5874ad55a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "  y_pred_test = pred_model(x_test.float().to(device))\n",
    "\n",
    "# Print test loss\n",
    "print(f'Test loss: {criterion(y_pred_test.reshape(-1), y_test.float().to(device)).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0l8MtgQ1w7i"
   },
   "source": [
    "Let's show the results on a map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "execution": {
     "iopub.execute_input": "2025-02-07T20:47:14.815258Z",
     "iopub.status.busy": "2025-02-07T20:47:14.814942Z",
     "iopub.status.idle": "2025-02-07T20:47:15.697321Z",
     "shell.execute_reply": "2025-02-07T20:47:15.696529Z",
     "shell.execute_reply.started": "2025-02-07T20:47:14.815236Z"
    },
    "id": "jMVfEZNS06IN",
    "outputId": "4eb5a9eb-0fe6-406b-fd58-2d9841e95280",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "m = Basemap(projection='cyl', resolution='c', ax=ax[0])\n",
    "m.drawcoastlines()\n",
    "ax[0].scatter(coords_test[:,0], coords_test[:,1], c=y_test, s=5)\n",
    "ax[0].set_title('True')\n",
    "\n",
    "m = Basemap(projection='cyl', resolution='c', ax=ax[1])\n",
    "m.drawcoastlines()\n",
    "ax[1].scatter(coords_test[:,0], coords_test[:,1], c=y_pred_test.cpu().reshape(-1), s=5)\n",
    "ax[1].set_title('Predicted')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "satclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
