{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Kaggle Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the AI for Good course! For the hands-on coding in this course, we will use Kaggle as a development environment. Kaggle is great because it can host notebooks, datasets, and models, and gives you 30 hours of GPU usage per week for free. The aim of this notebook is to get you set up in the Kaggle environment. In it, we'll read and write some data, run a function, and create a plot so you are good to go for the coming weeks. You are welcome to use your own development environment if you prefer,but you'll need to manage the packages and files and you won't receive support from us if you environment is causing bugs, so proceed at your own risk!\n",
    "\n",
    "For this notebook, since we'll use an LLM, enable the GPU on the right hand panel, \"GPU T4 x2\" and then check it is working with the line of code below. If CPU is returned try again. Note, you only have 30 hours per week so make sure you use your time where needed and for the computation only. Learn more about what the GPU options are: https://www.linkedin.com/pulse/kaggle-accelerators-comparison-rukshar-alam-ki9bc/\n",
    "\n",
    "Below is the chunk that loads on a fresh kaggle notebook, it includes some details on the resources available. You can explore more by selecting View (at top right of page) -> Show sidebar. In here (to right of page) are some clickable settings for the notebook, including compute resources used, location of persistance storage and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-02T21:05:19.182082Z",
     "iopub.status.busy": "2025-01-02T21:05:19.181848Z",
     "iopub.status.idle": "2025-01-02T21:05:19.561001Z",
     "shell.execute_reply": "2025-01-02T21:05:19.560209Z",
     "shell.execute_reply.started": "2025-01-02T21:05:19.182040Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test read, write "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's grab some images.. using following api https://pypi.org/project/bing-image-downloader/. For this section, ensure that you have internet enabled in the settings of the notebook on the right hand panel. You'll have to have a verified phone number on your Kaggle profile in order to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:05:19.562099Z",
     "iopub.status.busy": "2025-01-02T21:05:19.561749Z",
     "iopub.status.idle": "2025-01-02T21:05:24.284914Z",
     "shell.execute_reply": "2025-01-02T21:05:24.283865Z",
     "shell.execute_reply.started": "2025-01-02T21:05:19.562048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install bing-image-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:05:24.286361Z",
     "iopub.status.busy": "2025-01-02T21:05:24.286073Z",
     "iopub.status.idle": "2025-01-02T21:05:24.294835Z",
     "shell.execute_reply": "2025-01-02T21:05:24.294207Z",
     "shell.execute_reply.started": "2025-01-02T21:05:24.286338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from bing_image_downloader import downloader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-02T21:05:24.295994Z",
     "iopub.status.busy": "2025-01-02T21:05:24.295744Z",
     "iopub.status.idle": "2025-01-02T21:06:32.509259Z",
     "shell.execute_reply": "2025-01-02T21:06:32.508387Z",
     "shell.execute_reply.started": "2025-01-02T21:05:24.295965Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "downloader.download(\"child sad\", limit=5, output_dir=\"images\", adult_filter_off=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see on the side panel in \"Output\" that the image files are under \"kaggle/working/images\". Let's use `ls` to list the files here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:06:32.510537Z",
     "iopub.status.busy": "2025-01-02T21:06:32.510212Z",
     "iopub.status.idle": "2025-01-02T21:06:32.632786Z",
     "shell.execute_reply": "2025-01-02T21:06:32.631677Z",
     "shell.execute_reply.started": "2025-01-02T21:06:32.510512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%ls /kaggle/working/images/'child sad'/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:06:32.635463Z",
     "iopub.status.busy": "2025-01-02T21:06:32.635191Z",
     "iopub.status.idle": "2025-01-02T21:06:32.642402Z",
     "shell.execute_reply": "2025-01-02T21:06:32.641474Z",
     "shell.execute_reply.started": "2025-01-02T21:06:32.635441Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_display_images(image_dir):\n",
    "    \"\"\"\n",
    "    Load images from a directory, store them in a list, \n",
    "    and display their thumbnails with names.\n",
    "\n",
    "    Parameters:\n",
    "    image_dir (str): Directory containing image files.\n",
    "    \n",
    "    Returns:\n",
    "    images (list): List of PIL image objects.\n",
    "    image_names (list): List of image filenames.\n",
    "    \"\"\"\n",
    "    # 1. Load all images and store them in a list\n",
    "    images = []\n",
    "    image_names = []\n",
    "    \n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.lower().endswith(('jpg', 'jpeg')):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            images.append(Image.open(image_path))\n",
    "            image_names.append(filename)\n",
    "\n",
    "    # 2. Plot thumbnails of the images with their names\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "    if len(images) == 1:\n",
    "        axes = [axes]  # Ensure axes is iterable when there's only 1 image\n",
    "\n",
    "    for ax, img, name in zip(axes, images, image_names):\n",
    "        ax.imshow(img.resize((128, 128)))  # Resize for thumbnail\n",
    "        ax.set_title(name, fontsize=8)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return images, image_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:06:32.643679Z",
     "iopub.status.busy": "2025-01-02T21:06:32.643459Z",
     "iopub.status.idle": "2025-01-02T21:06:33.640014Z",
     "shell.execute_reply": "2025-01-02T21:06:33.639111Z",
     "shell.execute_reply.started": "2025-01-02T21:06:32.643660Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_dir = '/kaggle/working/images/child sad/'\n",
    "images, image_names = load_and_display_images(image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's grab some other, clearly different, images. Let's use the Bing Image Downloader again to get some images of happy children. Go ahead and write this line of code yourself. Limit the search to 5 images, output to the \"images\" directory, and leave the adult filter on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-02T21:06:33.641375Z",
     "iopub.status.busy": "2025-01-02T21:06:33.641035Z",
     "iopub.status.idle": "2025-01-02T21:06:37.339616Z",
     "shell.execute_reply": "2025-01-02T21:06:37.338746Z",
     "shell.execute_reply.started": "2025-01-02T21:06:33.641345Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use the Bing Image Downloader again to get some images of \"child happy\"\n",
    "# Limit the search to 5 images, output to the \"images\" directory, and leave the adult filter on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put these in the same directory to mix things up a bit.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:06:37.341041Z",
     "iopub.status.busy": "2025-01-02T21:06:37.340700Z",
     "iopub.status.idle": "2025-01-02T21:06:37.581996Z",
     "shell.execute_reply": "2025-01-02T21:06:37.580790Z",
     "shell.execute_reply.started": "2025-01-02T21:06:37.341009Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "source_dir = '/kaggle/working/images/child happy/'\n",
    "destination_dir = '/kaggle/working/images/child sad/'\n",
    "\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "for index, file in enumerate(os.listdir(source_dir)):\n",
    "    src = os.path.join(source_dir, file)\n",
    "    if os.path.isfile(src):\n",
    "        shutil.move(src, os.path.join(destination_dir, f\"image{index}{os.path.splitext(file)[1]}\"))\n",
    "\n",
    "%ls /kaggle/working/images/'child happy'/\n",
    "!rm -r /kaggle/working/images/'child happy'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our directory has some mixed up happy and sad images mixed in.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-02T21:06:37.583515Z",
     "iopub.status.busy": "2025-01-02T21:06:37.583242Z",
     "iopub.status.idle": "2025-01-02T21:06:39.195932Z",
     "shell.execute_reply": "2025-01-02T21:06:39.194888Z",
     "shell.execute_reply.started": "2025-01-02T21:06:37.583491Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%ls /kaggle/working/images/'child sad'/\n",
    "\n",
    "images, image_names = load_and_display_images('/kaggle/working/images/child sad/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting a Multimodal LLM with Images and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:06:39.197389Z",
     "iopub.status.busy": "2025-01-02T21:06:39.197043Z",
     "iopub.status.idle": "2025-01-02T21:06:52.272879Z",
     "shell.execute_reply": "2025-01-02T21:06:52.271905Z",
     "shell.execute_reply.started": "2025-01-02T21:06:39.197357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we didn't obtain these images from the internet. Imagine we had millions of pictures to evaluate not just these. How might we assess what we have? One option is to try some off-the-shelf models to help extract text based meaning from the images. And then see if we can enumerate from there. We'll be using the Hugging Face APIs for this... https://huggingface.co/tasks/image-text-to-text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function that takes a random selection of images and some text input and outputs some text for each image. It uses a small model ~1.7GB (0.5B params) so is not massively accurate. At the same time the individual descriptions are interesting. Don't worry too much about the technical details right now (this is just a demo set up notebook, and in future sessions we'll pre-empt any work done in notebooks in session with conceptual and theoretical backgrounds, but if interested here is the background paper https://arxiv.org/pdf/2407.07895)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:14:28.669240Z",
     "iopub.status.busy": "2025-01-02T22:14:28.668920Z",
     "iopub.status.idle": "2025-01-02T22:14:33.101620Z",
     "shell.execute_reply": "2025-01-02T22:14:33.100898Z",
     "shell.execute_reply.started": "2025-01-02T22:14:28.669215Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "# Load the model and processor once to avoid reloading them for each image\n",
    "model_id = \"llava-hf/llava-interleave-qwen-0.5b-hf\"\n",
    "device = \"cuda:0\"  # Assuming you're using GPU\n",
    "\n",
    "# Load model and processor\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    low_cpu_mem_usage=True\n",
    ").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Function to process and generate response for a given image and prompt\n",
    "def generate_response(image_path, prompt):\n",
    "    # Load image from the path\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Define a chat history and use `apply_chat_template` to get the correctly formatted prompt\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Apply chat template to the conversation\n",
    "    formatted_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "    # Process the inputs (text and image)\n",
    "    inputs = processor(formatted_prompt, image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate the output from the model\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "    # Decode and return the response\n",
    "    return processor.decode(output[0], skip_special_tokens=True), image\n",
    "\n",
    "# Function to randomly select a specified number of images from a directory and process them with a given prompt\n",
    "def process_multiple_random_images_from_directory(directory, prompt, num_images=5):\n",
    "    # List all image files in the directory (assuming image files are .jpg, .jpeg, or .png)\n",
    "    image_files = [f for f in os.listdir(directory) if f.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
    "    \n",
    "    # If no image files are found, return\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the directory.\")\n",
    "        return\n",
    "\n",
    "    # If the requested number of images exceeds the available ones, adjust\n",
    "    num_images = min(num_images, len(image_files))\n",
    "    \n",
    "    # Randomly select the specified number of images\n",
    "    selected_image_files = random.sample(image_files, num_images)\n",
    "    \n",
    "    # Process each randomly selected image\n",
    "    for selected_image_file in selected_image_files:\n",
    "        image_path = os.path.join(directory, selected_image_file)\n",
    "        print(f\"Processing randomly selected image: {selected_image_file}\")\n",
    "        response, image = generate_response(image_path, prompt)\n",
    "        \n",
    "        # Display the image and the response\n",
    "        display_image_with_response(image, response, selected_image_file)\n",
    "\n",
    "# Function to display an image and its corresponding model response\n",
    "def display_image_with_response(image, response, image_file):\n",
    "    # Create a figure and axes\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    \n",
    "    # Display the response as a title\n",
    "    plt.title(f\"Response for {image_file}:\\n{response}\", fontsize=12)\n",
    "    \n",
    "    # Show the image with response\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T22:14:33.102820Z",
     "iopub.status.busy": "2025-01-02T22:14:33.102606Z",
     "iopub.status.idle": "2025-01-02T22:14:39.293386Z",
     "shell.execute_reply": "2025-01-02T22:14:39.292371Z",
     "shell.execute_reply.started": "2025-01-02T22:14:33.102802Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "directory = \"/kaggle/working/images/child sad/\"\n",
    "prompt = \"Describe the contents of this image.\"\n",
    "\n",
    "# Example call to process 1 random image from a given directory\n",
    "process_multiple_random_images_from_directory(directory, prompt, num_images=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we check out the ability of the model to capture sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "directory = \"/kaggle/working/images/child sad/\"\n",
    "prompt = \"Is this image a happy scene or not?\"\n",
    "\n",
    "process_multiple_random_images_from_directory(directory, prompt, num_images=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo the above with your own prompt. Be creative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the model with your own prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting thing about the model above is that it can used to query multiple images at once. This might be useful for assessing the contents aross the set of images we have...might be worth exploring this later. How do you think it would do processing multiple images at one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you happen to want to clean up your working directory you can uncomment and run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-02T21:07:43.100610Z",
     "iopub.status.idle": "2025-01-02T21:07:43.100862Z",
     "shell.execute_reply": "2025-01-02T21:07:43.100763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!rm -r /kaggle/working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "### Part 1: Kaggle Setup\n",
    "This week, make sure you have done the following:\n",
    "1. Created an account on Kaggle\n",
    "2. Imported this notebook into Kaggle and run all of the cells.\n",
    "3. Fill in the empty code blocks as prompted. \n",
    "\n",
    "Deliverable: upload a screenshot of your Kaggle profile to Canvas so that we can share private datasets with you in future weeks.\n",
    "\n",
    "### Part 2: Python Assessments\n",
    "To see where everyone is with their familiarity with Python and ML, we'll have you complete 3 assessments on DataCamp. You will need to create an account, just use the free tier. You are not being graded on how well you do, but we want to see where everyone is at so we can figure out how to support you best. Go to https://www.datacamp.com/signal#assessments and take the following 3 assessments, screenshot the result, and upload it to Canvas:\n",
    "1. Python Programming\n",
    "2. Data Manipulation with Python\n",
    "3. Machine Learning Fundamentals in Python\n",
    "\n",
    "### Bonus\n",
    "Set up a personal website with a data science portfolio section to upload your work from each week to. This is a great way to showcase your work to future employers or advisors. You can use a free service like GitHub Pages, Netlify, WordPress, Wix, SquareSpace etc to create your site. Here's Isaiah's as an example: https://isaiahlg.com/portfolio/home.html.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
